{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Extracted 81 unique sample_tokens\n",
      "Number of unique sample_tokens: 81\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# Initialize empty lists to store the sample_tokens\n",
    "sample_tokens_cam = []\n",
    "sample_tokens_radar = []\n",
    "\n",
    "# Function to safely parse JSON data with numpy arrays\n",
    "def safe_json_loads(line):\n",
    "    try:\n",
    "        # Convert numpy arrays to lists before parsing\n",
    "        line = line.replace(\"array(\", \"\").replace(\")\", \"\")\n",
    "        line = line.replace(\"'\", \"\\\"\")\n",
    "        return json.loads(line)\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(f\"Error in parsing JSON at line: {line}\\n{e}\")\n",
    "        return None\n",
    "\n",
    "# Read and extract sample_tokens from output-cam file\n",
    "with open('output-cam.txt', 'r') as cam_file:\n",
    "    for line in cam_file:\n",
    "        data = safe_json_loads(line)\n",
    "        if data:\n",
    "            sample_token = data['sample_token']\n",
    "            if sample_token not in sample_tokens_cam:\n",
    "                sample_tokens_cam.append(sample_token)\n",
    "\n",
    "# Read and extract sample_tokens from output-RADAR file\n",
    "with open('output-RADAR.txt', 'r') as radar_file:\n",
    "    for line in radar_file:\n",
    "        data = safe_json_loads(line)\n",
    "        if data:\n",
    "            sample_token = data['sample_token']\n",
    "            if sample_token not in sample_tokens_radar:\n",
    "                sample_tokens_radar.append(sample_token)\n",
    "\n",
    "# Merge both lists to get 81 unique sample_tokens\n",
    "sample_tokens = list(set(sample_tokens_cam + sample_tokens_radar))\n",
    "\n",
    "print(\"Step 1: Extracted 81 unique sample_tokens\")\n",
    "print(\"Number of unique sample_tokens:\", len(sample_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def fix_json_format(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = file.read()\n",
    "    \n",
    "    try:\n",
    "        # Try to parse the JSON data to check if it's valid\n",
    "        json.loads(data)\n",
    "    except json.JSONDecodeError as e:\n",
    "        # If there's an error, fix the JSON formatting by replacing single quotes with double quotes\n",
    "        fixed_data = data.replace(\"'\", \"\\\"\")\n",
    "        \n",
    "        # Save the corrected data back to the file\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(fixed_data)\n",
    "\n",
    "# List of filenames to fix\n",
    "filenames = ['output-cam.txt', 'output-RADAR.txt', 'output-gt.txt']\n",
    "\n",
    "for filename in filenames:\n",
    "    fix_json_format(filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 2 column 1 (char 432)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n\u001b[1;32m     31\u001b[0m \u001b[39m# Read data from each file\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m output_cam_data \u001b[39m=\u001b[39m read_data(\u001b[39m'\u001b[39;49m\u001b[39moutput-cam.txt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     33\u001b[0m output_radar_data \u001b[39m=\u001b[39m read_data(\u001b[39m'\u001b[39m\u001b[39moutput-RADAR.txt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     34\u001b[0m output_gt_data \u001b[39m=\u001b[39m read_data(\u001b[39m'\u001b[39m\u001b[39moutput-gt.txt\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 28\u001b[0m, in \u001b[0;36mread_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_data\u001b[39m(filename):\n\u001b[1;32m     27\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filename, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m---> 28\u001b[0m         data \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mload(file)\n\u001b[1;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(fp, \u001b[39m*\u001b[39m, \u001b[39mcls\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_float\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, parse_constant\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, object_pairs_hook\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[39m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[39m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[39mreturn\u001b[39;00m loads(fp\u001b[39m.\u001b[39;49mread(),\n\u001b[1;32m    294\u001b[0m         \u001b[39mcls\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39mcls\u001b[39;49m, object_hook\u001b[39m=\u001b[39;49mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[39m=\u001b[39;49mparse_float, parse_int\u001b[39m=\u001b[39;49mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[39m=\u001b[39;49mparse_constant, object_pairs_hook\u001b[39m=\u001b[39;49mobject_pairs_hook, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/lib/python3.11/json/decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n\u001b[0;32m--> 340\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExtra data\u001b[39m\u001b[39m\"\u001b[39m, s, end)\n\u001b[1;32m    341\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Extra data: line 2 column 1 (char 432)"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Function to fix the JSON format\n",
    "def fix_json_format(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = file.read()\n",
    "\n",
    "    try:\n",
    "        # Try to parse the JSON data to check if it's valid\n",
    "        json.loads(data)\n",
    "    except json.JSONDecodeError as e:\n",
    "        # If there's an error, fix the JSON formatting by replacing single quotes with double quotes\n",
    "        fixed_data = data.replace(\"'\", \"\\\"\")\n",
    "\n",
    "        # Save the corrected data back to the file\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(fixed_data)\n",
    "\n",
    "# List of filenames to fix\n",
    "filenames = ['output-cam.txt', 'output-RADAR.txt', 'output-gt.txt']\n",
    "\n",
    "for filename in filenames:\n",
    "    fix_json_format(filename)\n",
    "\n",
    "# Function to read and process the data\n",
    "def read_data(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "# Read data from each file\n",
    "output_cam_data = read_data('output-cam.txt')\n",
    "output_radar_data = read_data('output-RADAR.txt')\n",
    "output_gt_data = read_data('output-gt.txt')\n",
    "\n",
    "# Extract unique sample tokens from both output-cam and output-RADAR\n",
    "sample_tokens_cam = {entry['sample_token'] for entry in output_cam_data}\n",
    "sample_tokens_radar = {entry['sample_token'] for entry in output_radar_data}\n",
    "unique_sample_tokens = sample_tokens_cam.union(sample_tokens_radar)\n",
    "\n",
    "# Filter output-gt data based on unique sample tokens\n",
    "filtered_gt_data = [entry for entry in output_gt_data if entry['sample_token'] in unique_sample_tokens]\n",
    "\n",
    "# Now, you have the filtered data for the learning task.\n",
    "# You can use the important attributes (translation, size, rotation, velocity, and name) for your learning model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
